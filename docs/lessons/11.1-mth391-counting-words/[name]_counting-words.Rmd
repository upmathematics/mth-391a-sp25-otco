---
title: "Counting Words"
subtitle: "Fundamentals of Data Science"
author: "[name]"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Syllabus Reminders

* You must submit your mini-assignment individually by end-of-class or end-of-day. Your name must exist in your mini-assignment and the names of your collaborators.
* Mini-assignments are marked mostly on completion, and partially on correctness. It will be marked either pass or fail, there will no detailed feedback on mini-assignments, and no opportunities for revisions and make-up.

# Instructions

* For the exercises, please provide your answers in full sentences.
* Write your answers by replacing the text "[Write your answer here]".
* Please read the problems fully and carefully before answering.
* When finished, knit this `.Rmd` to `.html`.
* Submit this `.Rmd` and the recently knitted `.html`.

# Packages

The following R packages have already been loaded for you, so there's no need to load them yourselfâ€”they will be used in the problem sets. If you need any additional packages, you can load them here as well.

```{r message=FALSE, warning=FALSE}
# load packages
library(tidyverse)

# text related packages
library(tidytext)
```

# Collaborators

::: {style="color: blue;"}
[Write your answer here]
:::

# Exercises

## Problem 1

Below is an R code chunk that load the data sets `avatar-the-last-airbender.csv` and the `starwars.csv` files. The file [`avatar-the-last-airbender.csv`](https://github.com/averyrobbins1/appa){target="_blank"} contains transcripts of all three seasons of the show "Avatar: Last Airbender". The file [`starwars.csv`](https://github.com/kamran786/Star-Wars-Movie-Scripts-Text-Analysis){target="_blank"} contains the transcripts of the 6 Star Wars movies. The code below also loads the stopwords lexicon.

```{r message=FALSE, warning=FALSE}
# load the stopwords lexicon
swd_list <- tidytext::stop_words %>% 
  filter(lexicon == "SMART") %>%
  select(word)
swd_list <- swd_list$word

# load the data sets
atla <- read_csv("avatar-the-last-airbender.csv")
sw <- read_csv("starwars.csv")
```

a. Examine the two data sets and identify which is structured, unstructured, or semi-structured. List and identify the types of variables for each data set.

::: {style="color: blue;"}
[Write your answer here]
:::

b. Using the Starwars data and the `tidytext` package to tokenize the text data, count the words in the text variable for each season/book/movie, filter out the stopwords, and visualize the top 15 words using a barplot. Below, is an example code for you to get started.

```{r}
### [BEGIN] - CHANGE DATA SET HERE
df <- atla
### [END] - CHANGE DATA SET HERE

### [BEGIN] - WORK ON YOUR DATA WRANGLING HERE
# tokenize text and count words
df_counts <- df %>% 
  # group by season/book/movie
  group_by(book) %>%
  # automatically tokenizes the text and puts them into the word variable
  unnest_tokens(word, full_text) %>% 
  # use the count function to get the frequency of each word
  count(word) %>%
  # filter out the stopwords using the stopwords list defined earlier
  filter(!word %in% swd_list) %>%
  # count the frequency of each word in each group
  arrange(desc(n))
### [END] - WORK ON YOUR DATA WRANGLING HERE
```

::: {style="color: blue;"}
[Write your answer here]
:::
